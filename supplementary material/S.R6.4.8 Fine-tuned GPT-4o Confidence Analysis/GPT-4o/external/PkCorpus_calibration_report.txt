================================================================================
CONFIDENCE CALIBRATION ANALYSIS
Dataset: PkCorpus
================================================================================

PREDICTION OUTCOMES
--------------------------------------------------------------------------------
TP:    2 ( 50.0%)
TN:    1 ( 25.0%)
FP:    1 ( 25.0%)
FN:    0 (  0.0%)
Total:    4

CALIBRATION ANALYSIS
--------------------------------------------------------------------------------
Correct predictions (n=3):
  Mean confidence:  0.9997 (SD: 0.0003)
  Median:           0.9999

Incorrect predictions (n=1):
  Mean confidence:  0.9997 (SD: nan)
  Median:           0.9997

TRUE POSITIVES vs FALSE POSITIVES (Critical for Label Noise)
--------------------------------------------------------------------------------
True Positives (n=2):
  Mean:  0.9999 (SD: 0.0000)

False Positives (n=1):
  Mean:  0.9997 (SD: nan)

================================================================================
SUGGESTED TEXT FOR PAPER
================================================================================

To verify that high sensitivity reflects genuine discriminative ability rather
than uniform positive bias, we analyzed GPT-4o's prediction confidence via
log-probabilities on the PkCorpus. Correct predictions exhibited
significantly higher confidence (mean logprob: 1.00, SD: 0.00)
than incorrect predictions (mean: 1.00, SD: nan).

