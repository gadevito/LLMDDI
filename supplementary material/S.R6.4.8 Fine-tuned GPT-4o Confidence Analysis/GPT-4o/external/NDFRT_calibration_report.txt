================================================================================
CONFIDENCE CALIBRATION ANALYSIS
Dataset: NDFRT
================================================================================

PREDICTION OUTCOMES
--------------------------------------------------------------------------------
TP:  119 ( 50.0%)
TN:  115 ( 48.3%)
FP:    4 (  1.7%)
FN:    0 (  0.0%)
Total:  238

CALIBRATION ANALYSIS
--------------------------------------------------------------------------------
Correct predictions (n=234):
  Mean confidence:  0.9992 (SD: 0.0029)
  Median:           1.0000

Incorrect predictions (n=4):
  Mean confidence:  0.6582 (SD: 0.4257)
  Median:           0.7694

TRUE POSITIVES vs FALSE POSITIVES (Critical for Label Noise)
--------------------------------------------------------------------------------
True Positives (n=119):
  Mean:  0.9991 (SD: 0.0026)

False Positives (n=4):
  Mean:  0.6582 (SD: 0.4257)

================================================================================
SUGGESTED TEXT FOR PAPER
================================================================================

To verify that high sensitivity reflects genuine discriminative ability rather
than uniform positive bias, we analyzed GPT-4o's prediction confidence via
log-probabilities on the NDFRT. Correct predictions exhibited
significantly higher confidence (mean logprob: 1.00, SD: 0.00)
than incorrect predictions (mean: 0.66, SD: 0.43).

