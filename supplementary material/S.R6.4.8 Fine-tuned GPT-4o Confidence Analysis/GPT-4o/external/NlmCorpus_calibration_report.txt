================================================================================
CONFIDENCE CALIBRATION ANALYSIS
Dataset: NlmCorpus
================================================================================

PREDICTION OUTCOMES
--------------------------------------------------------------------------------
TP:    8 ( 44.4%)
TN:    8 ( 44.4%)
FP:    1 (  5.6%)
FN:    1 (  5.6%)
Total:   18

CALIBRATION ANALYSIS
--------------------------------------------------------------------------------
Correct predictions (n=16):
  Mean confidence:  0.9995 (SD: 0.0011)
  Median:           0.9999

Incorrect predictions (n=2):
  Mean confidence:  0.9502 (SD: 0.0146)
  Median:           0.9502

TRUE POSITIVES vs FALSE POSITIVES (Critical for Label Noise)
--------------------------------------------------------------------------------
True Positives (n=8):
  Mean:  0.9997 (SD: 0.0006)

False Positives (n=1):
  Mean:  0.9398 (SD: nan)

================================================================================
SUGGESTED TEXT FOR PAPER
================================================================================

To verify that high sensitivity reflects genuine discriminative ability rather
than uniform positive bias, we analyzed GPT-4o's prediction confidence via
log-probabilities on the NlmCorpus. Correct predictions exhibited
significantly higher confidence (mean logprob: 1.00, SD: 0.00)
than incorrect predictions (mean: 0.95, SD: 0.01).

